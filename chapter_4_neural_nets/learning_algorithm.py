# 前提
'''
神经网络存在合适的权重和偏置,调整权重和偏置以便拟合训练数据的过程称为'学习'
'''
# 神经网络的学习分成下面四个步骤
# 步骤一 mini-batch
'''
从训练数据中随机选出一部分数据,这部分数据称为mini-batch
我们的目标是减小mini-batch的损失函数的值
'''
# 步骤二 计算梯度
'''
为了减小mini-batch的损失函数的值,需要求出各个权重参数的梯度.
梯度表示损失函数的值减小最多的方向
'''
# 步骤三 更新参数
'''
将权重参数沿梯度方向进行微小更新
'''
# 步骤四 重复
'''
重复步骤一 步骤二 步骤三
'''
# 随机梯度下降法 stochastic gradient descent SGD
